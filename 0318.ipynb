{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "98b48052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f10d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184eed09ab5748df8109acd42a8a8247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12018131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. klt2000을 사용하여 명사 추출\n",
    "klt2000_output_file = open('ilbe_comments.txt', 'r', encoding='utf-8')\n",
    "\n",
    "klt2000_output_tmp = klt2000_output_file.readlines()\n",
    "klt2000_output = []\n",
    "tmp = []\n",
    "\n",
    "for token in tqdm(klt2000_output_tmp):\n",
    "    token_info = token.split(':')\n",
    "    \n",
    "    if token_info[2] == '뷁뷁뷁\\n':\n",
    "        klt2000_output.append(tmp)\n",
    "        tmp = []\n",
    "        continue\n",
    "    \n",
    "    if token_info[1] == 'N' or token_info[1] == 'P' or token_info[1] == '1':\n",
    "        tmp.append(token_info[2].replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db01c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. kcc150으로 학습된 word2vec 모델을 불러온다.\n",
    "model = Word2Vec.load('word2vec-KCC150.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d701fbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9776f23b5849c68c20798b3b9bc8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f188015acaf14d9c9f82f70239fbc8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3205c59a4f4447ea8691cab5f780cd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b34bff15a8442a5ac119948046c87ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b491fdacf9fe47adaa2fd65f7c0779e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff4863fc0b9406695751fb5e3d9616d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2725479c2e5344c089ed34943bca5120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c3152d0fc24ba1b41d7abba955777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dfb3a0ae3a48459798b86a8a8a5fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55f2da90b44162b948df13e5905084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. word2vec에서 시드 어휘와 비슷한 유사도를 가지고 관련있는 것으로 사전 구축\n",
    "hate_dict1 = ['혐오']\n",
    "hate_dict2 = ['멸시']\n",
    "hate_dict3 = [i[0] for i in model.wv.most_similar('욕설', topn=3)]\n",
    "hate_dict4 = [i[0] for i in model.wv.most_similar('인종차별', topn=3)]\n",
    "hate_dict5 = [i[0] for i in model.wv.most_similar('조롱', topn=2)]\n",
    "hate_dict = []\n",
    "\n",
    "for word in tqdm(hate_dict1):\n",
    "    words = model.wv.most_similar(word, topn=3)\n",
    "\n",
    "    for i in words:\n",
    "        if i[1] > 0.705 and i[0] not in hate_dict1:\n",
    "            hate_dict1.append(i[0])\n",
    "        \n",
    "        if i[1] <= 0.705:\n",
    "            break\n",
    "            \n",
    "for word in tqdm(hate_dict1):\n",
    "    if model.wv.similarity(hate_dict1[0], word) > 0.605 and word not in hate_dict:\n",
    "        hate_dict.append(word)\n",
    "        \n",
    "for word in tqdm(hate_dict2):\n",
    "    words = model.wv.most_similar(word, topn=3)\n",
    "\n",
    "    for i in words:\n",
    "        if i[1] > 0.705 and i[0] not in hate_dict2:\n",
    "            hate_dict2.append(i[0])\n",
    "        \n",
    "        if i[1] <= 0.705:\n",
    "            break\n",
    "            \n",
    "for word in tqdm(hate_dict2):\n",
    "    if model.wv.similarity(hate_dict2[0], word) > 0.605 and word not in hate_dict:\n",
    "        hate_dict.append(word)\n",
    "        \n",
    "for word in tqdm(hate_dict3):\n",
    "    words = model.wv.most_similar(word, topn=3)\n",
    "\n",
    "    for i in words:\n",
    "        if i[1] > 0.705 and i[0] not in hate_dict3:\n",
    "            hate_dict3.append(i[0])\n",
    "        \n",
    "        if i[1] <= 0.705:\n",
    "            break\n",
    "            \n",
    "for word in tqdm(hate_dict3):\n",
    "    if model.wv.similarity(hate_dict3[0], word) > 0.605 and word not in hate_dict:\n",
    "        hate_dict.append(word)\n",
    "        \n",
    "for word in tqdm(hate_dict4):\n",
    "    words = model.wv.most_similar(word, topn=2)\n",
    "\n",
    "    for i in words:\n",
    "        if i[1] > 0.705 and i[0] not in hate_dict4:\n",
    "            hate_dict4.append(i[0])\n",
    "        \n",
    "        if i[1] <= 0.705:\n",
    "            break\n",
    "            \n",
    "for word in tqdm(hate_dict4):\n",
    "    if model.wv.similarity(hate_dict4[0], word) > 0.605 and word not in hate_dict:\n",
    "        hate_dict.append(word)\n",
    "        \n",
    "for word in tqdm(hate_dict5):\n",
    "    words = model.wv.most_similar(word, topn=3)\n",
    "\n",
    "    for i in words:\n",
    "        if i[1] > 0.705 and i[0] not in hate_dict5:\n",
    "            hate_dict5.append(i[0])\n",
    "        \n",
    "        if i[1] <= 0.705:\n",
    "            break\n",
    "            \n",
    "for word in tqdm(hate_dict5):\n",
    "    if model.wv.similarity(hate_dict5[0], word) > 0.605 and word not in hate_dict:\n",
    "        hate_dict.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "25ca06ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc01827f7fa426787f14a2de716bea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 모든 문장에 대해서 klt2000으로 추출된 명사를 어휘집에 있는 단어 모두와 유사도를 계산하여 합산\n",
    "# 4-1. 합산된 값의 평균을 구하여 그 문장의 최종 score로 설정\n",
    "output = []\n",
    "\n",
    "for sent in tqdm(klt2000_output[:10]):\n",
    "    value = 0\n",
    "    \n",
    "    for token in sent:\n",
    "        if token in model.wv.index_to_key:\n",
    "            for hate in hate_dict:\n",
    "                value += model.wv.similarity(hate, token)\n",
    "                \n",
    "    if len(sent) == 0:\n",
    "        output.append(0)\n",
    "    else:\n",
    "        output.append(value/len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3f4a5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2. 계산된 값 저장\n",
    "import pickle\n",
    "\n",
    "with open('output_tmp.pkl', 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2f751e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3. 계산된 값 복구\n",
    "with open('output_tmp.pkl', 'rb') as f:\n",
    "    output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "020a7b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.799934431289633  /  좀더 시간이 흘러야 진실이 혹은 진실에 가깝게 밝혀질듯\n",
      "2.8215604719516705  /  근데 나이 60에 저정도원한이면 보통감정이쌓인게 아닌건 확실함은퇴하고 조용히 여생보낼준비할때인데 것도 임원출신이 칼부림이라니 막장인생칼부림하곤 무게가 다름\n",
      "1.564551204707151  /  ㄹㅇ 시발 임원출신이면 노후걱정없이 ㅆㅅㅌㅊ로 살다 자연사할운명인데그런 이점이 모두안보일정도로 이성을 잃은듯싶다 ㅋㅋㅋㅋ\n",
      "4.333185963332653  /  죽여도 무죄\n",
      "1.1894375147065148  /  근데 은행권이 성희롱 성추행 전나심함 ㅋㅋ 전에 사귄여친이 은행원이였는데 듣고 놀랐다 이기야\n",
      "1.8612180322874337  /  증권쪽도ㅇㅇㅇㅇ그래서 사직하고 백수로 스폰이나 하고다니는여자봄. 외모 ㅅㅌㅊ이고 외국계 다녔는데\n",
      "0.4348881607875228  /  존나 특이한케이스네\n",
      "1.2542885219946684  /  그집아빠가 딸보고 일하지말라고 했다고함아빠는 작은사업체 운영하고있음 지금은 여자나이가 30중반일걸백수된게 10년쯤전\n",
      "2.335157385458135  /  은행권 애들 직장내 성희랑 장난아님.2차 노래방가면 브루스추고 난리 아니라더라.\n",
      "0.07017005015707885  /  ㅇㅇ 성희롱 성추행 사례모음집 보면 거의다 은행권에서 나온거\n",
      "2.854197633396185  /  오늘 죽은 사람 : 6년전에 가해자가 성범죄 저질렀디고 허위 고발 ⟩ 재판결과 무죄⟩ 가해자 복직⟩ 가해자가 소송 진행하면서 쓴 변호사비 공금횡령이라 시비털음⟩ 가해자가 빡쳐서 범행이라고 적혀있네\n",
      "0.535825179395033  /  그냥 ^대구^ 한마디로 요약가능\n",
      "3.6574683315702714  /  모든 인간은 칼 앞에 평등하다 ㄷㄷ\n",
      "2.016412189346738  /  무죄 땅 땅! 크\n",
      "3.049783449143029  /  원래 국민이 재판, 처벌의 힘을 국가에 맡기는게 사적으로 처벌하는 거보다 공정하고확실한 일처리를 요구해서 그렇게 하는 건데 시발 이 따위로 하면 폴아웃이나 북두의 권처럼서로 알아서 처벌하고 다니는 시대가 더 공정하지.\n",
      "0  /  ㅋ\n",
      "2.084233636735007  /  히틀러가 시급하다\n",
      "0.20479922700906172  /  홍어들이 또...\n",
      "3.579962005489506  /  나 같으면 그냥 죽이진 않고 팔다리 자르고 평생 고통스럽게 살다 뒤지게 만들어줄듯\n",
      "0  /  왜그리 빨리 저승가고 싶어했을까\n",
      "2.857400076696649  /  대쪽 같은 대구사람 ㅜㅜ 명예살인 쌉 린정\n",
      "0  /  죽어도 싼년들임 ㅋㅋㅋㅋㅋㅋ\n",
      "0.3585783646752437  /  새마을 아재ㅇㅂ\n",
      "0.4264761833806655  /  무죄는 에바고집행유예나 5년형이 적당한 듯\n",
      "1.2822053587224218  /  성수아부지노\n",
      "0  /  ㅇㅂ\n",
      "5.731943167746067  /  그래도 살인은 아니지..\n",
      "5.26477781299036  /  ㅇㅇ 살인을 옹호 할수없음그러나 인과응보라고 봄\n",
      "4.101678122533485  /  아무리 그래도 사람을 죽이면 안돼지..차라리 염산을 얼굴에 뿌리지\n",
      "3.2647771870251745  /  그럼 나중에 또 복수당하잖아\n",
      "1.5440422259271145  /  일반인이니깐 염산구하기가 쉽겠냐...\n",
      "3.402609654236585  /  그건 플랜B나였으면 염산 뿌리고 가족들을 죽인다평생 지가 한짓에 고통받다가 자살하게^^^^^^^\n",
      "2.6545764262943217  /  저 심정 알겠다..딸바보상사가 전후관계 파약안하고 여직원말만 듣고 징계위원회 회부하겠다고 헛소리하다가..역관광시켜 버린적있음\n",
      "0  /  얼마나 빡쳤으면 막나갔겠노\n",
      "8.073924168944359  /  악의적인 행동이 상대방을 악하게 만든다는걸 모름 ㅋㅋㅋ\n",
      "8.39164387434721  /  존경합니다\n",
      "0  /  와 김치년들 ㅈ같노\n",
      "0.1274000650582214  /  ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 개꿀이노 새마을금고 개잡쓰레기 보지구녕에 연탄박은년 ㅋㅋㅋㅋ 메갈여시 개씹창년 정회원년 하나 뒤졌네ㅋㅋㅋㅋㅋ\n",
      "2.9991305357631064  /  불의를 법이 어떻게 해결해주리~조선은 그렇게 사는거지~\n",
      "4.37770339846611  /  저거는 감형 해줘야지\n",
      "0.05647424448397942  /  추운겨울 간만에 훈훈한 소식\n",
      "1.0337833026005683  /  잘죽였네. 전 임직원분 음독자살시도하셨다는데 별탈 없길..\n",
      "0  /  죽어도 싼 놈년\n",
      "1.1676671104913112  /  본인이 직접 판결을 내리셧구만... 총기 허용이 시급하다\n",
      "2.4920381474851943  /  새마을 열사는 영원할꺼다진짜 무고죄는 곱게 못놔둘듯\n",
      "3.4442270186943156  /  솔직히 나같아도 막장 테크 탔을 거다.저런 무고와 불합리, 남은 인생을 치욕과 억울함속에서 살아야 될 바엔, 쓰레기 새끼들 잘되는 꼴 안보고 목숨건 심판을 행할거다.물론, 마음은 굴뚝 같지만 목숨걸 용기가 없어서, 실행에 옮기는건 장담못하는데, 막상 닥치면 그딴 갈등없이 실행할듯\n",
      "0.49390385366859846  /  ㄹㅇ 어차피 60대면 살만큼 살았으니 뒤지기전에 한녀죽이고 빵에가서 조용히 여생보내는게 나을듯\n",
      "2.585968723571252  /  60대면 가진게 더 많은 시기라서 저런 결심하는거 쉽지 않을 것임결혼도 안한놈들도 아니고, 재산, 가족 노후를 즐길일만 남았는데, 성추행 무고죄가 밝혀졌는데, 저지랄로 또다시 엮어들어가니법으로는 도저히 해결이 안되는 상황이니 극단의 선택을 한것이지...그만큼 좃같은 년놈들로 자신이 휘둘리고, 치욕을 당하느니 뽄때를 보여준것이지\n",
      "1.5711331488359974  /  그건 고시원에서 노가다나뛰면서 동네 틀딱들이랑 막걸리나쳐마시고 세상탓하는 잃을거없는 고독사가 운명인 틀딱이고은행임원 출신이면 이야기가 다르지60대에 은행임원이면 최소 자산 5억은모아놧을테고 자기명의 집까지있을텐데결혼도한거같고저런잃읗거많은 틀딱들은 나이들면 들수록 현명해진다근데 저런짓할정도면 원한이 보통이 아닌거다\n",
      "-1.2155147504527122  /  씹창년들 잘뒈졌다지옥행 예약이노 ㅋㅋㅋㅋ\n",
      "1.5561530874110758  /  새마을열사 무죄\n",
      "3.4835250522349575  /  허위사실과 보복성 악의를 품은것 때문에 정의의 심판 받은것.이걸로 대한민국은 성에괸한 법의 폐해가 막심하단걸 꼭 알아야한다.법개선에 평등이 이뤄지지 않으면 더욱 직접정의가 실현되는 나라가되고 막장국가됨 근디 이걸 민좃딩이 해내네 ㅋㅋ\n",
      "0  /  꺼어어어어억\n",
      "0.8122009995762104  /  사실이라면 대호 성수 같은 케이스네\n",
      "1.6844868651719678  /  저정도로 놀려먹으려고 븅신같은 마음 먹었으면 피해자 아마 소송 수 년간 피말렸을걸송사 진행되고 일사천리로 해결되는게 아니라 변론기일 마감 1시간 전 뭐 30분전 이딴식으로 내용진술 변론서 증명서 서면으로 띡 보내면 시발 당일 소송건 다음으로 연기 또 같은 방식으로 연기연기연기하다보면 3년지나있음ㅋㅋㅋㅋㅋㅋ저건 하루이틀 짧은 시간에 걸쳐서 원한 생긴게 아니네 가해자들 분명 저딴식으로 피해자 정신적으로 수년간 존나 괴롭혀서 생긴 셀프 원한이었을걸 거기에 무죄로 끝났는데 시발롬들 또 무고하고자빠졌네 뒤질려고 환장한새끼네보통 저딴식으로 깽판치고 피해자 주변에서 순삭하고 잠수타는게 보통인데ㅋㅋㅋㅋㅋㅋㅋ\n",
      "3.29660156207795  /  저 나쁜 가해자는 피해자에게 반성의 기회도 주지 않았네.저렇게 그냥 뒤지면 반성할 기회가 전혀 없지만낮짝에 염산 맞으면 수삽년동안 반성할 기회가 있잖아.\n",
      "1.6905816221260466  /  염산을 꼭뿌리자.염산^^!!!!무고녀 염산캠페인!\n",
      "2.4307979056611657  /  염산 부카케!\n",
      "2.412698834178445  /  한국인들, 특히 여자들은 선을 지킬 줄 모르는거 같다조선은 일본처럼 지나다가 시비 붙으면 막장 사무라이새끼들이 칼침부터 놓던 역사도 없고, 미국처럼 총부터 쏘고보던 카우보이 역사도 없어서 그런건가?누구나 마음 속에 함무라비 법전 하나씩 가지고 있고, 선 넘는 순간 임계점 돌파하면 진짜 뭔 사고든 터질텐데 이걸 아예 모름인생막장이 칼 휘두르는거랑 임원출신에 노후안정된 사람이 휘두르는 칼의 무게는 다르다. 오죽했으면 저랬겠노\n",
      "0.04916887101717293  /  고담대구는 여전하구나= □=..\n",
      "0  /  오태식이 돌아왔구나\n",
      "6.921218138188124  /  왠지는 모르겠는데 뭔가 존나 시원한 느낌\n",
      "1.3522655743727228  /  종족 대구면서 주무기인 불안쓰고 칼쓴거 보면 많이 봐준듯\n",
      "0  /  베트맨 ㅇㅂ\n",
      "2.3991408167639747  /  원래 법이 나를 보호하지못하면 실행뿐이다\n",
      "4.874296545982361  /  직접 심판한거구나..\n",
      "2.792702879756689  /  이글 이제서야 인기글왔네 ㄷㄷ\n",
      "1.40471317328047  /  비질란테 ㅇㅂ\n",
      "4.121215827103394  /  근데 살인보단 눈이나 팔다리 하나 불구 만들어버리는게 더 낫지 않냐죽음은 찰나의 고통 후에 찾아오는 영면인데불구로 꾸역꾸역 불행함을 느끼며 살아가게 하는게 더 복수지\n",
      "-0.6291424573864788  /  불구만들면 또 보복ㄹ하러온다.\n",
      "2.5324983501244183  /  개다가 치료비+ 뭐 저 뒤진새기들 심보 보니 어케든 복수하려고 발버둥 칠텐데 그냥 죽이는게 젤 속편할듯\n",
      "3.5153160491536255  /  평생 타인의 도움을 받어야만 살아갈수있게 두 손 두 발 사지절단하고얼굴에는 성형수술도 못할정도로 염산을 부어버림.단 한쪽 눈만큼은 자기얼굴 볼수있게 자비심을 배풀어 온전하게 놔둠.\n",
      "1.2341562590678223  /  근데 막상 저상황되서 찌르다 보면 멈춰지지않아서 죽여버리게 되는듯 ..이미 눈돌아가버린 상황이라보통 우발적 살인이 아닌 계획 살인의 경우 칼을 수십방 찔러 죽이는 경우가 많음\n",
      "3.8276938680792227  /  사실이라면 칼로 쥰나 쑤셔서 보답하는게 옳다고 봄!ㅇㅂ\n",
      "5.385004114592448  /  이유야 어쨋건간에 60이면 노친네구만 ㅉㅉ 양심도없노 이기야\n",
      "0.1762173886721333  /  정의구현 정상참작 집행유예해야지\n",
      "5.883062906563282  /  그래도 여자를 죽인건 잘못한거야\n",
      "6.590170664367179  /  여자들은 폭력에 무지하여 이런 결과를 예상치 못한거지\n",
      "1.9101766906678677  /  정의?로운스토리였잖아??\n",
      "1.7871436609530065  /  이런일 남의 일이 아님나도 전에 개 조커튼 상무 송씨 ㄱㅅㄲ가 날 짜를려고 여직원들 회유 하여 성추행 했다고 허위진술 하게 했었으니깐내가 ㄹㅇ 성격이 무던한 편이라 걍 넘어 갔지만 이런글 보면 좀 야마가 반 쯤은 돔\n",
      "3.2719846664528762  /  죽어서 다행이다감옥가서 형을 살더라도 속은 시원할거같다안죽었는데 살인미수같은걸로 몇년 살바에 다 죽이고 몇년 더 사는게 정신건강에 훨씬 도움이 된다진짜 통쾌하다\n",
      "4.701193509623408  /  사연이 있는줄 알았더니 그냥 미친놈이었네\n",
      "5.820685953309294  /  늙으면 장수 햇다고 축하할일이아닌죄악이라고 비난 받아야 할일임 ㄹㅇ\n",
      "3.16015450831037  /  역시 잘해주면안되 저런새끼들은 그냥 굶어 뒤지는게 맞는것같다 ㅋㅋ\n",
      "2.9388855685579722  /  저 주인 할머니 언젠간 열받아서 밥에 약탈것깉다 ㄹㅇ 사람이라는게 마냥 선 하지않거든\n",
      "1.003572996146977  /  맞다ㅋㅋ 나도 길냥이 챙겨주다보니 이새끼가 자꾸 밥달라 앵앵거려서 목비틀고 꼬리잡고 바닥에 내리찍여죽임ㅋㅋ 시체는 낙엽담는 마대에 넣어뒀는데 담날보니 수거해갔더라ㅋㅋ\n",
      "0  /  이래서 헬조선에서는 남 도와주면 안된다.\n",
      "3.4221548184286803  /  선행이라는 생각 조차 안 했다는 거네. 아줌마 현타 오겠노\n",
      "1.349661301530432  /  경찰불러\n",
      "2.218591390643269  /  ㅎㅎㅎ 죽쒀서 개줫구만 저새끼 수원역에서 내리던데 전철은 칼같이 돈내고탐\n",
      "4.907661984208971  /  저 분식집 아주머니왠지 기독교 믿는사람일듯\n",
      "-0.2989747026003897  /  떡볶이 먹고싶다 ㅇㅅㅠ\n",
      "6.0236678421497345  /  조만간 칼부림 나겠네\n",
      "2.392516305048048  /  돈냈다고 생각해서 당당한게 아니라 돈냈다고 우기기땜에 당당한거지 저거 지도 돈안낸거 암\n",
      "5.583902782469522  /  편집증이나 정신분열 있는 사람은 진짜라고 믿음\n",
      "2.7009049113839865  /  틀딱까는글 ㅇㅂ멍청한틀선족들 자기네들 까는글인줄도모르고 ㅇㅂ박는수준 ㅋㅋㅋ\n",
      "5.049737613182515  /  그냥 정신병환자임.\n",
      "4.734798842313467  /  심보 보니예전에노무현 지지했을 듯\n",
      "2.1453146380372345  /  사이다 아니라서 답답해 ㅠ.ㅜ\n",
      "2.376156959682703  /  니가 원하는 결말은 뭔데?\n"
     ]
    }
   ],
   "source": [
    "# 5. 최종 score가 결정된 약 100 ~ 200개의 문장을 sampling하여 score의 기준을 설정\n",
    "ilbe_c = pd.read_csv('ilbe_comments.csv')\n",
    "\n",
    "for i, j in zip(output[:100], ilbe_c['댓글'].tolist()[:100]):\n",
    "    print(i, ' / ', j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fea663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 추가적으로 문장을 sampling하여 score 기준에 대한 정확도 검사 후 모든 문장에 대해서 이 방법을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b342edc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['혐오',\n",
       " '증오',\n",
       " '경멸',\n",
       " '증오심',\n",
       " '멸시',\n",
       " '모멸',\n",
       " '적대감',\n",
       " '혐오감',\n",
       " '죄의식',\n",
       " '열등감',\n",
       " '천대',\n",
       " '핍박',\n",
       " '냉대',\n",
       " '푸대접',\n",
       " '폭언',\n",
       " '막말',\n",
       " '욕설',\n",
       " '인종차별적',\n",
       " '인종차별',\n",
       " '모욕',\n",
       " '모독',\n",
       " '모멸감',\n",
       " '모욕감',\n",
       " '굴욕감',\n",
       " '수치심']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70e8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
